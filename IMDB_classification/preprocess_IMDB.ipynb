{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = pd.read_csv(\"./data/IMDB_dataset.csv\")\n",
    "imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word-level tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(list(imdb[\"review\"]))\n",
    "temp = tokenizer.texts_to_sequences(list(imdb[\"review\"]))\n",
    "word_engineered = pad_sequences(temp, maxlen=200, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   32,  4636,  2468, ...,   125,  4103,   486],\n",
       "       [    3,   393,   120, ...,     0,     0,     0],\n",
       "       [   10,   190,    11, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [    1, 17184,   519, ..., 22840,     2,  6050],\n",
       "       [   16, 11491,    20, ...,    67,   739,    42],\n",
       "       [   54,    27,  5892, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   10,   190,    11,    13,     3,   393,    95,     5,  1155,\n",
       "          55,    20,     3,    96,   879,  1494,  2657,  1241,     8,\n",
       "           1,   903, 16061,   769,     2,   147,     3,   649,  2333,\n",
       "         202,     1,   111,     6,  4086,    18,     1,   410,     6,\n",
       "        1915,     2,     1,   102,    23,  1485,    57,     1,    69,\n",
       "        6126,  6686,  1574,   494,   136,    47,   200,    26,   680,\n",
       "          50,    33,   959,    11,     6,    21,  1026,   220,   230,\n",
       "        2917,  5196,    10,   190,     9,    13,  3059,    12,  2971,\n",
       "        2050,     6,   130,  1403,     8,  1139,     4,     1,   396,\n",
       "         106,     4,   176,    25,  2079,     5,   112,     7,     7,\n",
       "          11,    13,     1,    88,   482,  1451,    30,    27,     4,\n",
       "       19396,  1317,     8,   153,  3024,    10,   131,     3,  2121,\n",
       "         136,   198,   110,    75,  1508,    16,  8927, 38711,     8,\n",
       "          11,    59,  1323,     5,  1260,   175,    40,  1257,  1428,\n",
       "           2,  5078,   203,    82,     3,   848,    18,  3611,   186,\n",
       "         257,     7,     7,    11,   200,    21,    26,     1,  7241,\n",
       "        5176,     4,    24,   628,    18,     9,    13, 31140,    71,\n",
       "        2244,  2930, 24416,     2,    51,   218,    71,  2658,     3,\n",
       "          78,   202,     5,   139,    63,    16,   350,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_engineered[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### char-level tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_tokenizer = Tokenizer(char_level=True, oov_token=\"<UNK>\")\n",
    "char_tokenizer.fit_on_texts(list(imdb[\"review\"]))\n",
    "temp = char_tokenizer.texts_to_sequences(list(imdb[\"review\"]))\n",
    "char_engineered = pad_sequences(temp, maxlen=200, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write into tfrecord format \n",
    "\n",
    "tfrecord 라는 것은 데이터(=tensor)를 저장하기 위한 고유의 텐서 흐름 이진형식이다.       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfsample_path = \"./data/number.tfrecord\"\n",
    "with tf.io.TFRecordWriter(tfsample_path) as file_writer:\n",
    "    for _ in range(4):\n",
    "        x, y = np.random.random(), np.random.random()\n",
    "        record_bytes = tf.train.Example(features=tf.train.Features(feature={\n",
    "            \"x\": tf.train.Feature(float_list=tf.train.FloatList(value=[x])),\n",
    "            \"y\": tf.train.Feature(float_list=tf.train.FloatList(value=[y])),\n",
    "        })).SerializeToString()\n",
    "    \n",
    "        file_writer.write(record_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"x\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.6362333297729492\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"y\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.4968804121017456\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"x\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.0618320032954216\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"y\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.9925841093063354\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"x\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.3288733661174774\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"y\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.5355156660079956\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "features {\n",
      "  feature {\n",
      "    key: \"x\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.5774037837982178\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"y\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.5665009021759033\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tfrecord 읽어보기 \n",
    "# novdov.github.io 참고 \n",
    "\n",
    "\n",
    "num_sample = tf.data.TFRecordDataset(tfsample_path)\n",
    "for aRecord in num_sample:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(aRecord.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. Th has type str, but expected one of: bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e222059aaf90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         record_byte = tf.train.Example(features = tf.train.Features(feature={\n\u001b[1;32m     11\u001b[0m             \u001b[0;34m\"wordSeq\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint64_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt64List\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwordSeq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint64_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt64List\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         })).SerializeToString()\n",
      "\u001b[0;31mTypeError\u001b[0m: \"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. Th has type str, but expected one of: bytes"
     ]
    }
   ],
   "source": [
    "labels = [1 if x == \"positive\" else 0 for x in imdb[\"sentiment\"]]\n",
    "\n",
    "example_path = \"./data/imdb_tfrecord.tfrecord\"\n",
    "with tf.io.TFRecordWriter(example_path) as file_writer:\n",
    "    for idx in range(word_engineered.shape[0]):\n",
    "        wordSeq = word_engineered[idx]\n",
    "        sentence = imdb[\"review\"][idx]\n",
    "        label = labels[idx]\n",
    "        \n",
    "        record_byte = tf.train.Example(features = tf.train.Features(feature={\n",
    "            \"wordSeq\": tf.train.Feature(int64_list = tf.train.Int64List(value=wordSeq)), \n",
    "            \"sentence\": tf.train.Feature(bytes_list = tf.train.BytesList(value=[sentence])), \n",
    "            \"label\": tf.train.Feature(int64_list = tf.train.Int64List(value=[label]))\n",
    "        })).SerializeToString()\n",
    "        file_writer.write(record_byte)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imdb[\"review\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
